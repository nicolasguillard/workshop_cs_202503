{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop CentraleSupélec - CeSIA - Partie 3\n",
    "\n",
    "- Création : 02/2025 par [Nicolas Guillard](mailto:nicolas.guillar@securite-ia.fr) - bénévole au [CeSIA](https://www.securite-ia.fr/).\n",
    "\n",
    "Créer en s'inspirant particulièrement de [Générer des noms de villes et communes françaises](https://github.com/alxndrTL/villes) par [Alexandre TL](https://www.youtube.com/@alexandretl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation du sujet et Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les éléments de ce TP :\n",
    "- le présent carnet,\n",
    "  \n",
    "(et ceux qui seront installés grâce au script `Installation de l'environnement de travail`),\n",
    "- le répertoire `./utils` et les fichiers contenus,\n",
    "- le répertoire `./weights` contenant les poids des modèles utiles et ceux produits,\n",
    "- le répertoire `./images` contenant les illustrations des carnets,\n",
    "- le fichier de données `./villes.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation de l'environnement de travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le script ci-dessous est destiné à installer les éléments nécessaires au fonctionnement de ce carnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "repo = \"workshop_cs_202503\"\n",
    "branch = \"main\"\n",
    "url_repo = f\"https://github.com/nicolasguillard/{repo}/archive/refs/heads/{branch}.zip\"\n",
    "target_dir = (\n",
    "  \"/content\"\n",
    "  if IN_COLAB\n",
    "  else \".\"\n",
    ")\n",
    "resources = [\"utils\", \"weights\", \"images\", \"villes.txt\"]\n",
    "\n",
    "if not Path(f\"{target_dir}/utils\").exists() :\n",
    "  print(\"=== Installation des ressources utiles à ce carnet ===\")\n",
    "  !wget -P {target_dir} {url_repo}\n",
    "  !unzip {target_dir}/{branch}.zip -d {target_dir}\n",
    "  for resource in resources:\n",
    "    !mv {target_dir}/{repo}-{branch}/{resource} {target_dir}/{resource}\n",
    "  !rm -rf {target_dir}/{repo}-{branch}\n",
    "  !rm -f {target_dir}/{branch}.zip\n",
    "  print(\"=== Terminé ===\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    print(\"--- Rafraichissez au besoin la liste des fichiers à gauche si nécessaire ---\")\n",
    "else:\n",
    "  print(\"Il semble que des ressources nécessaires pour ce carnet soient déjà installés :\")\n",
    "  for resource in resources:\n",
    "    print(\"\\t\", f\"./{resource}\", \"présent\" if Path(f\"{target_dir}/{resource}\").exists else \"absent\")\n",
    "  print(\"Pour supprimer les ressources automatiquement installées, utilisez la fonction 'remove_resources()' dans un autre bloc de code.\")\n",
    "\n",
    "def remove_resources():\n",
    "  !rm -rf {target_dir}/{repo}-{branch}\n",
    "  for resource in resources:\n",
    "    !rm -rf {target_dir}/{resource}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les modules et paramétrages globaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modules nécessaires sont importés. A moins d'un besoin spécifique, il n'y aura pas besoin de modifier le bloc de code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules prédéfinis et tiers\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules créés pour le projet\n",
    "from utils import get_datasets, SOS, EOS, PAD\n",
    "from utils import print_color, load_transformer_model, TransformerConfig, LanguageModel\n",
    "from utils import clean_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélection du GPU selon l'environnement de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer la limite du nombre maximal de lignes affichées dans un tableau pandas\n",
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer le thème de seaborn\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrer les graines aléatoires\n",
    "#pth_rnd_gen_device = torch.Generator(device).manual_seed(42)\n",
    "if device == \"cuda\":\n",
    "    pth_rnd_gen_device = torch.cuda.manual_seed(42)\n",
    "elif device == \"mps\":\n",
    "    pth_rnd_gen_device = torch.mps.manual_seed(42)\n",
    "pth_rnd_gen_cpu = torch.manual_seed(42)\n",
    "pth_rnd_gen = pth_rnd_gen_cpu if device == \"cpu\" else pth_rnd_gen_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de concepts avec l'utilisation d'un SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le principe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de séparer et de distinguer les possibles caractéristiques instriquées dans des neurones polysémantiques, nous allons utiliser un Sparse Auto-Encoder.\n",
    "\n",
    "![](https://drive.google.com/uc?id=1_Y3mIiTL1RgQ5nXMgyxBG7SIz5PfGXWz)\n",
    "\n",
    "![Utilisation du SAE](./images/sae_with_model.png)\n",
    "\n",
    "Il s'agira donc de récupérer les activations fournies par une (la par défaut) couche `DecodeLaeyr` dans le modèle de langue `LanguageModel` et de s'en servir d'abord pour l'entrainement du SAE, puis pour l'interprétation des caractéristiques apprises (en espérant que les neurones de la couche cachée soient surtout monosémantiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition d'un modèle de SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Sparse auto-encoder est donc composé d'une couche cachée qu'on appelera \"activations cachées du SAE\". Il prend en entrée les activations générée par un module `DecoderLayer`. Voici un schéma :\n",
    "\n",
    "![](https://drive.google.com/uc?id=1Txvhbzkrp7aKlFnZ62ANAeqW7JdXHTuA)\n",
    "\n",
    "![SAE](./images/sae.png)\n",
    "\n",
    "avec `nb_caract` le nombre de caractéristiques à distinguer et `d_model` la dimension interne au modèle de langue.\n",
    "\n",
    "Mathématiquement, son fonctionnement peut-être exprimé ainsi :\n",
    "\n",
    "$\\text{encode}(x) = \\text{ReLU}((x - b_{\\text{dec}}) \\ @ \\ W_{\\text{enc}} + b_{\\text{enc}})$\n",
    "\n",
    "et\n",
    "\n",
    "$\\text{decode}(h) = h \\ @ \\ W_{\\text{dec}} + b_{\\text{dec}}$\n",
    "\n",
    "avec :\n",
    "\n",
    "- $@$ : multiplication matricielle\n",
    "\n",
    "\n",
    "> Conseil(s) :\n",
    "> - $W_{\\text{enc}}$, $W_{\\text{dec}}$, $b_{\\text{dec}}$ et $b_{\\text{enc}}$ sont des instances de la classe `nn.Parameter`;\n",
    "> - la création des instances $W_{\\text{enc}}$ et $W_{\\text{dec}}$ prend pour paramètre un tenseur vide qui est initialisé avec la fonction `torch.nn.init.kaiming_uniform_`;\n",
    "> - la création des instances $b_{\\text{dec}}$ et $b_{\\text{enc}}$ prend pour paramètre un tenseur replis de zéros;\n",
    "> - se rappeler que les dimensions de `x` seront (batch, séquence taille de la sortie d'un `DecoderLayer`);\n",
    "> - se rappeler que les dimensions de la sortie du SAE seront aussi (batch, séquence taille de la sortie d'un `DecoderLayer`);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCICE(S) : Définition de la classe d'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter les méthodes d'initialisation `__init()`, `encode()` et `decode()` à partir des explications fournies précédemment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, act_size: int, num_features: int, l1_coeff: float) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1_coeff = l1_coeff\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.W_enc = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        self.b_enc = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "\n",
    "        self.W_dec = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        self.b_dec = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "\n",
    "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "        # DEBUT DE BLOC\n",
    "        ### EXERCICE : à compléter\n",
    "        return None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        # FIN DE BLOC\n",
    "    \n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "        # DEBUT DE BLOC\n",
    "        ### EXERCICE : à compléter\n",
    "        return None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        # FIN DE BLOC\n",
    "\n",
    "    def reconstruct_loss(self, x: torch.Tensor, acts: torch.Tensor, x_reconstruct: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        l2_loss = (x_reconstruct.float() - x.float()).pow(2).sum(-1).mean(0) # loss de reconstruction MSE\n",
    "        l1_loss = self.l1_coeff * (acts.float().abs().sum()) # penalité L1 sur les activations des concepts\n",
    "        return l1_loss, l2_loss\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor] :\n",
    "        \"\"\"\n",
    "        Args :\n",
    "            x : input (B, S, act_size = d_model) ou (B*S, act_size = d_model)\n",
    "        \"\"\"\n",
    "        hidden_acts = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        x_reconstruct = None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "\n",
    "        l1_loss, l2_loss = self.reconstruct_loss(x, hidden_acts, x_reconstruct)\n",
    "        loss = l2_loss + l1_loss # loss total\n",
    "\n",
    "        return loss, x_reconstruct, hidden_acts, l2_loss, l1_loss\n",
    "    \n",
    "    # permet de stabiliser l'entraînement\n",
    "    @torch.no_grad()\n",
    "    def make_decoder_weights_and_grad_unit_norm(self):\n",
    "        W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
    "        W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n",
    "        self.W_dec.grad -= W_dec_grad_proj\n",
    "        # Bugfix(?) for ensuring W_dec retains unit norm, this was not there when I trained my original autoencoders.\n",
    "        self.W_dec.data = W_dec_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCICE(S) : Adaptation de la définition du Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut modifier la méthode de propagation `forward()` de la classe `AutoEncoder` afin de récupérer les activations de la couche cachée si le paramètre `act`vaut `True`. Pour cela, on va créer une classe `AutoEncoderForSAE` qui héritera de l'ensemble des éléments de la classe parent, et qui disposera de la méthode `forward()` avec des modifications à apporter, selon les explications fournies.\n",
    "\n",
    "> Conseil(s) :\n",
    "> - prendre en considération la définition de la méthode `forward()` de la classe `Transformer`;\n",
    "> - il s'agit donc d'intercepter le résultat d'un calcul intermédiaire réalisé durant la propagation avec la classe `LanguageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelForSAE(LanguageModel):\n",
    "    def __init__(self, model_config: TransformerConfig) -> None:\n",
    "        super().__init__(model_config)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, act: bool = False, stop_at_layer: int = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args :\n",
    "            tokens (torch.Tensor) : input shaped (B, s, vocab_size) with s in [1; S]\n",
    "            act (bool) : if True, return hidden activation (the last layer by default, if stop_at_layer not provided)\n",
    "            stop_at_layer (int) : return the ouput (activations) after the specified {layer}-th layer (1 -> n_layers)\n",
    "        \"\"\"\n",
    "        act = act or (stop_at_layer != None)\n",
    "        \n",
    "        ### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "        # DEBUT DE BLOC\n",
    "        ### EXERCICE : à compléter\n",
    "        return None  ### EXERCICE : remplacer None par les bonnes instructions\n",
    "        # FIN DE BLOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La phase d'entrainement du SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les hyperparamètres fournis pour la création du SAE et son entrainement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 32 # dimension du modèle\n",
    "n_heads = 4 # nombre de têtes pour l'attention\n",
    "n_layers = 1 # nombre de couches\n",
    "dropout = 0.\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, tokenizer, _ = get_datasets(\"./villes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chargement du modèle de langue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des poids du modèle appris dans la partie 2, ou sinon le fichier `./weights/solutions/model_32__4_heads__1_layers.pth` en remplacement si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(\n",
    "    vocab_size=tokenizer.vocabulary_size(),\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    dropout=dropout,\n",
    "    max_len=max(train_dataset.max_len, test_dataset.max_len) - 1  # Because X and y : sequence[:-1] and sequence[1:] in dataset\n",
    ")\n",
    "\n",
    "filename = \"./weights/model_32__4_heads__1_layers.pth\" # A modifier selon le contexte\n",
    "#filename = \"`./weights/solutions/model_32__4_heads__1_layers.pth`\" # A décommenter selon le contexte\n",
    "model = load_transformer_model(filename, class_model=LanguageModelForSAE, config=config, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Création du SAE associé au modèle de langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_size = config.d_model\n",
    "num_features = 4 * config.d_model\n",
    "sae = AutoEncoder(act_size=act_size, num_features=num_features, l1_coeff=3e-4)\n",
    "optim = torch.optim.Adam(sae.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCICES(s) : la boucle d'entrainement du SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter les instructions de la boucle d'instruction en tenant compte des explications fournies précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae.to(device)\n",
    "sae.train()\n",
    "\n",
    "for epoch in trange(epochs, desc=\"apprentissage\"):\n",
    "    train_loss = 0\n",
    "    for X, y in tqdm(train_dataloader, total=len(train_dataloader), desc=f\"epoch #{epoch+1}\"):\n",
    "        X = X.to(device) # (B, S)\n",
    "        y = y.to(device) # (B, S)\n",
    "\n",
    "        # on les fait passer dans le modèle et on récupère les activations de la couche cachée du modèle \n",
    "        # (grâce à act=True)\n",
    "        ### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "        # DEBUT DE BLOC\n",
    "        ### EXERCICE : à compléter    \n",
    "        #loss, ... ### EXERCICE : remplacer \"loss, ...\" par la bonne instruction. Seul loss est utilisé\n",
    "        # FIN DE BLOC\n",
    "        \n",
    "        train_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        # opération explicite de normalisation avant propagation dans la chaîne de calcul\n",
    "        sae.make_decoder_weights_and_grad_unit_norm()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f\"\\tperte entrainement: {loss.item():.2f}\")\n",
    "\n",
    "sae.eval();\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sauvegarde des poids du SAE\n",
    "\n",
    "> Conseil : si vous souhaitez entrainer plusieurs fois le même SAE avec des hyperparamètres différents, initialiser la variable `timestamp` ci-dessous à `True`. Cela provoquera l'ajout d'un marqueur temporel au format \"`YYYYMMDD-HHMMSS`\" dans le nom du fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = False\n",
    "filename = f\"./weights/sae_model_{d_model}__{n_heads}_heads__{n_layers}_layers\"\n",
    "if timestamp:\n",
    "    filename += \"__\" + datetime.datetime.now().strftime(\"%Y%M%d-%I%M%S\")\n",
    "filename += \".pth\"\n",
    "torch.save(sae.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si dans l'environnement Colab, sauvegarde dans Google Drive pour utiliser le fichier sauvé dans un autre carnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  if not Path('/content/drive').exists():\n",
    "    drive.mount('/content/drive')\n",
    "  target_dir_drive = '/content/drive/MyDrive'\n",
    "  if not Path(f\"{target_dir_drive}/{repo}\").exists() :\n",
    "    !mkdir {target_dir_drive}/{repo}\n",
    "  filename_drive = filename.replace(\"/weights/\", f\"/{repo}/\")\n",
    "  !cp {target_dir}/{filename} {target_dir_drive}/{filename_drive}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des poids du SAE appris s'ils du modèle ont déjà été sauvés. Autrement, possibilité d'utiliser le fichier `./weights/solutions/sae_model_32__4_heads__1_layers.pth` en remplacement si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_load_sae = False # mettre à True four forcer le chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sae(filename: str, act_size: int, num_features: int, device=\"cpu\", verbose: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load weigths from a file and instanciate a SAE object\n",
    "    \"\"\"\n",
    "    sae = AutoEncoder(act_size=act_size, num_features=num_features, l1_coeff=3e-4)\n",
    "    sae.load_state_dict(\n",
    "        torch.load(filename, map_location=torch.device('cpu'), weights_only=True)\n",
    "        )\n",
    "    if verbose:\n",
    "        print(sae)\n",
    "    return sae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_load_sae:\n",
    "    sea_weights = \"./weights/sae_model_32__4_heads__1_layers.pth\" # A modifier selon le contexte\n",
    "    #sea_weights = \"./weights/solutions/sae_model_32__4_heads__1_layers.pt\" # A décommenter selon le contexte\n",
    "    act_size = config.d_model\n",
    "    num_features = 4 * config.d_model\n",
    "    sae = load_sae(sea_weights, act_size=act_size, num_features=num_features, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les fréquences d'activation des caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut identifier les neurones de caractéristiques dans les SEA en mesurant leur fréquence d'activation, quelque soit la valeur d'activation, ou selon ces valeurs.\n",
    "\n",
    "Ci-dessous, grâce à la fonction `freq_activations_rate()`, on calcule le ratio d'activation pour un jeu de données. On les convertit en pourcentage avant d'afficher les plus et les moins importants (c'est à dure les plus et moins fréquent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequence d'activations des features sur les données d'entrainement\n",
    "def freq_activations_rate(\n",
    "        model: LanguageModel,\n",
    "        sae: AutoEncoder,\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "        ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args :\n",
    "        - dataloader (torch.utils.data.Dataloader) : jeu de données\n",
    "\n",
    "    Returns :\n",
    "        - (torch.Tensor) le taux d'activation de chaque neurone interne du sae \n",
    "        basé sur le nombre total d'éléments de séquence, par séquence, sur l'ensemble\n",
    "        du jeu de données\n",
    "    \"\"\"\n",
    "    acts_count = torch.zeros((num_features,))\n",
    "    for X, _ in tqdm(dataloader, total=len(dataloader), desc=\"données de test\"):\n",
    "        X = X.to(device) # (B, S)\n",
    "        hidden_acts_transfo = model(X, act=True).view(-1, config.d_model)\n",
    "        _, _, features, _, _ = sae(hidden_acts_transfo) # (B*S, d_model)\n",
    "        features = features.to(\"cpu\")\n",
    "        acts_count += ((features > 0).int()).sum(0)\n",
    "\n",
    "    return acts_count / (len(dataloader.dataset) * dataloader.dataset.max_len)\n",
    "\n",
    "freq_rate = freq_activations_rate(model, sae, train_dataloader)\n",
    "\n",
    "n = 20\n",
    "values, indices = freq_rate.topk(n)\n",
    "print(f\"Les {n} neurones s'activant le plus fréquemment :\")\n",
    "display(pd.DataFrame({\"neurones\": indices, \"Freq (%)\": values*100}))\n",
    "\n",
    "n = 20\n",
    "values, indices = freq_rate.topk(n, largest=False)\n",
    "print(f\"Les {n} neurones s'activant le moins fréquemment :\")\n",
    "display(pd.DataFrame({\"neurones\": indices, \"Freq (%)\": values*100}))\n",
    "\n",
    "#for v, i in zip(values, indices):\n",
    "#    print(f\"neurone {i:3d} : {v:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCICE(S) : Pour les données d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous permet d'afficher la fraction (et le nombre exact) des neurones qui s'activent dans moins de 10% des cas (à savoir pour chaque élément de chaque séquence sur l'ensemble du jeu de données). Compléter ce code afin d'afficher la fraction s'activant dans moins de 1%, 0,1% et 0,01% des cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation : features > 0\n",
    "rate = (freq_rate < 1e-1).float().mean()\n",
    "print(f\"fraction des caractéristiques avec une fréquence d'activation < 10% : {rate * 100:.3f}% ({int(rate * num_features)})\")\n",
    "\n",
    "### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "# DEBUT DE BLOC\n",
    "### EXERCICE : à compléter\n",
    "# FIN DE BLOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCICE(S) : Pour les données de tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduisez les mêmes résultats avec le jeu de données de test, en réutilisant le code précédent (très peu de modification, vraiment). Puis comparez-les avec ceux obtenus avec le jeu d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "# DEBUT DE BLOC\n",
    "### EXERCICE : à compléter\n",
    "\n",
    "# FIN DE BLOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Des visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons si nous pouvons réaliser des analyses visuelles pour constater des résultats, ou en tout cas savoir si ce type de méthode d'analyse sont utiles.\n",
    "\n",
    "Récupérer les différentes actications cachées du Transformer et du SAE pour une séquence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = next(iter(train_dataloader)) # (B, S)\n",
    "\n",
    "idx_sequence = 1\n",
    "hidden_acts_transfo = model(X[idx_sequence-1:idx_sequence].to(device), act=True).view(-1, config.d_model) # (B*L, d_model)\n",
    "_, act_recon, features, _, _ = sae(hidden_acts_transfo)\n",
    "\n",
    "hidden_acts_transfo = hidden_acts_transfo.to(\"cpu\").detach()\n",
    "features = features.to(\"cpu\").detach()\n",
    "act_recon = act_recon.to(\"cpu\").detach()\n",
    "\n",
    "# Affichons les dimensions de ces variables pour vérifier :\n",
    "print(\"hidden_acts_transfo :\", hidden_acts_transfo.size())\n",
    "print(\"features :\", features.size())\n",
    "print(\"act_recon :\", act_recon.size())\n",
    "\n",
    "print(\"> nom :\", tokenizer.to_string(X[idx_sequence-1].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations cachées du Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons la succession de ces activations pour la séquence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "im1 = axes.imshow(hidden_acts_transfo, cmap=\"coolwarm\")\n",
    "plt.xlabel(\"position du neurone\")\n",
    "plt.ylabel(\"position dans la séquence\")\n",
    "plt.title(f\"Activation dans la couche cachée du Transformer\")\n",
    "fig.colorbar(im1, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations cachées du Transformer, pour un élément donné de la séquence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on se concentre sur un des éléments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_elt_seq = 7\n",
    "plt.imshow(hidden_acts_transfo[idx_elt_seq].view(1, -1), cmap=\"coolwarm\")\n",
    "plt.xlabel(\"position du neurone\")\n",
    "plt.gca().yaxis.set_visible(False)\n",
    "plt.title(f\"Activation dans la couche cachée du Transformer\\npour le {idx_elt_seq+1}ème élément de la séquence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations des caractéristiques pour toute la séquence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, regardons la succession de ces activations pour la séquence :\n",
    "\n",
    "**Question :**\n",
    "Sachant que dans l'image ci-dessous les abscisses représentent les indices des caractérisrtiques, et les ordonnées chaque élément de la séquence. Quelle interprétation peut-on formuler de cette illustration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "im1 = axes.imshow(features, cmap=\"coolwarm\")\n",
    "plt.xlabel(\"position du neurone\")\n",
    "plt.ylabel(\"position dans la séquence\")\n",
    "plt.title(\"Activation dans la couche cachée du SAE\")\n",
    "fig.colorbar(im1, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations des caractéristiques pour un élément d'une séquence donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[idx_elt_seq].view(4, -1), cmap=\"coolwarm\")\n",
    "plt.xlabel(\"position du neurone (modulo 32)\")\n",
    "plt.gca().yaxis.set_visible(False)\n",
    "plt.title(f\"Activation des neurones dans la couche cachée du SEA\\npour le {idx_elt_seq+1}ème élément de la séquence\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(features[idx_elt_seq].view(1, -1), cmap=\"coolwarm\")\n",
    "plt.xlabel(\"position du neurone\")\n",
    "plt.gca().yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations successives d'une caractéristique dans le SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_feature = 16\n",
    "plt.imshow(features[:, idx_feature].view(-1, 1), cmap=\"coolwarm\")\n",
    "plt.gca().xaxis.set_visible(False)\n",
    "plt.title(f\"Activation du {idx_feature+1}ème neurone dans la couche cachée du SAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Les activations dans le Transformer et leurs reconstructions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :**\n",
    "Sachant que dans l'image ci-dessous les abscisses représentent les indices des activations des neurones cachées dans le Transformer, et les ordonnées chaque élément de la séquence. Quelle interprétation peut-on formuler de cette illustration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de données pour les images\n",
    "image1 = hidden_acts_transfo.numpy()\n",
    "image2 = act_recon.numpy()\n",
    "\n",
    "# Créer une figure avec deux sous-graphiques côte à côte\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "# Afficher la première image\n",
    "im1 = axes[0].imshow(image1, cmap=\"coolwarm\")\n",
    "axes[0].set_title('Activations cachées')\n",
    "axes[0].set_xlabel(\"position du neurone\")\n",
    "axes[0].set_ylabel(\"position dans la séquence\")\n",
    "fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Afficher la deuxième image\n",
    "im2 = axes[1].imshow(image2, cmap=\"coolwarm\")\n",
    "axes[1].set_xlabel(\"position du neurone\")\n",
    "axes[1].set_title('Activations reconstruites')\n",
    "fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Afficher la différence\n",
    "diff = np.abs(image2 - image1) / image1 * 100\n",
    "im3 = plt.imshow(diff, cmap=\"coolwarm\")\n",
    "axes[2].set_xlabel(\"position du neurone\")\n",
    "axes[2].set_title('Différence (%)')\n",
    "fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la perte du modèle de langue en cas d'utilisation des reconstructions à la place des activations initiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "for i, (X, y) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    hidden_acts_transfo = model(X, act=True).view(-1, config.d_model)\n",
    "    _, act_recon, features, _, _ = sae(hidden_acts_transfo)\n",
    "    logits = model.get_logits_(act_recon)\n",
    "\n",
    "    total_loss += F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        y.view(-1).long(),\n",
    "        ignore_index=tokenizer.char_to_int[PAD]\n",
    "        )\n",
    "    #print(i, total_loss.item())\n",
    "\n",
    "print(f\"Train reconstruction loss : {total_loss.item()/len(train_dataloader):.2f}\")\n",
    "\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "for i, (X, y) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    hidden_acts_transfo = model(X, act=True).view(-1, config.d_model)\n",
    "    _, act_recon, features, _, _ = sae(hidden_acts_transfo)\n",
    "    logits = model.get_logits_(act_recon)\n",
    "\n",
    "    total_loss += F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        y.view(-1).long(),\n",
    "        ignore_index=tokenizer.char_to_int[PAD]\n",
    "        )\n",
    "    #print(i, total_loss.item())\n",
    "\n",
    "print(f\"Test reconstruction loss : {total_loss.item()/len(test_dataloader):.2f}\")\n",
    "\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration des neurones et concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Des neurones interprétables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va essayer de découvrir quelles caractéristiques ont été apprises par le modèle, en essayant d'interpréter les neurones d'une des (par défaut dans notre cas, de la...) couches cachées dans le Transformer.\n",
    "\n",
    "Le principe consiste à préserver les N valeurs d'activation (et les indices de l'entrée alors fournie au modèle) les plus grandes dans des tenseurs nommés `top_values` et `new_values`, grâce à la fonction `update_top_k()`.\n",
    "\n",
    "![](https://drive.google.com/uc?id=1_YDTcDw3dy57rmOKu3yAI5XF2y_PnHhb)\n",
    "\n",
    "![SAE activations max](./images/sae_max.png)\n",
    "\n",
    "Les appels successifs de cette fonction vont permettre de déterminer par paquets/batchs les valeurs d'activations (et leur indice) les plus grandes prises par les neurones cachées dans le Tranformer (cf l'utilisation en dessous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_top_k(\n",
    "        top_values: torch.Tensor,\n",
    "        top_indices: torch.Tensor,\n",
    "        new_values: torch.Tensor,\n",
    "        new_indices: torch.Tensor,\n",
    "        k: int) -> Tuple[: torch.Tensor, : torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        -\n",
    "    \"\"\"\n",
    "    combined_values = torch.cat([top_values, new_values])\n",
    "    combined_indices = torch.cat([top_indices, new_indices])\n",
    "    new_top_values, topk_indices = torch.topk(combined_values, k)\n",
    "    new_top_indices = combined_indices[topk_indices]\n",
    "    \n",
    "    return new_top_values, new_top_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple d'utilisation de `update_top_k()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 2 # Nombre maximum de valeurs à préserver par série\n",
    "N = 3 # Nombre d'élements distincts dans une série\n",
    "\n",
    "# Initialisation d'un batch de 4 séries\n",
    "test_batch = torch.tensor([\n",
    "    # Elt 0, 1, 2\n",
    "    [1, 2000, 30],      # serie 0\n",
    "    [10, 20, 300],      # serie 1\n",
    "    [1000, 2, 3],       # serie 2\n",
    "    [100, 200, 3000],   # serie 3\n",
    "])\n",
    "\n",
    "# Recherche des topK max par élément distinct, sur les 4 séries du batch, et des indiques des séries\n",
    "# dans lesquelles la valeur max est présente\n",
    "top_values = torch.zeros((N, topK), dtype=torch.int32)\n",
    "top_indices = torch.full((N, topK), -1, dtype=torch.long)\n",
    "for n in range(N):\n",
    "    dim_values = test_batch[:, n]\n",
    "    dim_indices = n + torch.arange(test_batch.size(0))\n",
    "    print(dim_values)\n",
    "    top_values[n], top_indices[n] = \\\n",
    "            update_top_k(top_values[n], top_indices[n], dim_values, dim_indices, topK)\n",
    "\n",
    "expected_top_values = torch.tensor([\n",
    "    [1000,  100],   # topK valeurs max pour l'élément 0\n",
    "    [2000,  200],   # topK valeurs max pour l'élément 1\n",
    "    [3000,  300]    # topK valeurs max pour l'élément 2\n",
    "    ])\n",
    "expected_top_indices = torch.tensor([\n",
    "    [2, 3],         # indices des séries correspondant aux topK de l'élément 0\n",
    "    [1, 4],         # indices des séries correspondant aux topK de l'élément 1\n",
    "    [5, 3]          # indices des séries correspondant aux topK de l'élément 2\n",
    "    ])\n",
    "\n",
    "print(\"top_values\", top_values)\n",
    "print(\"top_indices\", top_indices)\n",
    "\n",
    "assert torch.equal(expected_top_values,  top_values), f\"Valeurs inattendues dans top_values\"\n",
    "assert torch.equal(expected_top_indices,  top_indices), f\"Valeurs inattendues dans top_indices\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence avec des valeurs minimales (`-inf`) et des indices arbitraires ($-1$).\n",
    "\n",
    "- `top_values`, de taille (nb_neurones_cachés, top_k), répertorie les `top_k` plus grandes valeurs d'activations max de chaque neurone,\n",
    "- `top_indices`, de taille (nb_neurones_cachés, top_k), répertorie les indices qui correspondent à ces valeurs (indices=indice dans le dataset=indice d'un nom de commune dans le jeu de données d'entrainement)\n",
    "avec nb_neurones_cachés : nombre de neurones dans la couche concernée du Trasformer, c'est à dire `d_model`.\n",
    "\n",
    "Pour chaque paquet/batch :<br>\n",
    "   - on fait passer le batch dans le réseau,<br>\n",
    "   - on récupère les activations (B, S, nb_neurones_cachés) = nb_acts activations (une activation par neurone) pour chaque élément de séquence (S) pour chaque élément de batch, c.à.d un nom de commune (B),<br>\n",
    "   - on prend en compte l'activation maximale (selon la position).<br>\n",
    "\n",
    "Pour chaque neurone :<br>\n",
    "   - on utilise la fonction `update_top_k` pour mettre à jour `top_values` et `top_indices`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 20 # on garde les 20 exemples qui font s'activer le plus chaque neurone caché du Transformer\n",
    "\n",
    "# Les plus petites valeurs possibles\n",
    "top_values = torch.full((config.d_model, top_k), -float('inf'))\n",
    "# indices à -1 (le dernier) du fait que les plus petites valeurs seront classées en dernier dans top_vales\n",
    "top_indices = torch.full((config.d_model, top_k), -1, dtype=torch.long)\n",
    "\n",
    "#Pour chaque élément du jeu de données d'entrainement\n",
    "for X, _ in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "    # par lot\n",
    "    X = X.to(device)\n",
    "    # récupération des activations cachées du Transformer\n",
    "    hidden_acts_transfo = model(X, act=True) # (B, L, d_model)\n",
    "    # transfert vers le \"cpu\"\n",
    "    hidden_acts_transfo = hidden_acts_transfo.to(\"cpu\")\n",
    "    # récupération la valeur maximale d'activation de chaque neurone cachée dans le Transformer, par batch\n",
    "    max_act = hidden_acts_transfo.max(dim=1).values # (B, d_model)\n",
    "\n",
    "    # pour chaque neurone caché du Transformer\n",
    "    for id_neuron in range(config.d_model):\n",
    "        # récupérer l'ensemble des valeurs d'activation de ce neurone\n",
    "        dim_values = max_act[:, id_neuron]\n",
    "        # calcul des indices pour chaque valeur d'activation (rappel: une par élément de batch)\n",
    "        dim_indices = id_neuron + torch.arange(train_dataloader.batch_size)\n",
    "\n",
    "        # compilation des valeurs d'activations maximum selon l'indice du nom de commune dans le jeu de données d'entrainement\n",
    "        top_values[id_neuron], top_indices[id_neuron] = \\\n",
    "            update_top_k(top_values[id_neuron], top_indices[id_neuron], dim_values, dim_indices, top_k)\n",
    "\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des k neurones cachés du Transformer ayant les plus fortes activations, et les indices (dans jeu d'entrainement) des noms de communes associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_activations, indices = top_values[:, 0].topk(k=25)\n",
    "print(\"valeurs maximales : \", max_activations.tolist())\n",
    "print(\"indices des neurones correspondants : \", indices.tolist())\n",
    "max_activations_indices = top_indices[indices][0].tolist()\n",
    "print(\"indices des noms de communes dans le jeu d'entrainement\", max_activations_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un neurone caché choisi via son indice dans [0; `d_model`-1], on affiche les `topK` noms de communes liés aux plus grandes valeurs d'activation détectées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_hidden_activation = indices[0]\n",
    "for i in top_indices[id_hidden_activation]:\n",
    "    data_i, _ = train_dataset[i.item()]\n",
    "    data_i = data_i.to(device)\n",
    "    city_name = tokenizer.to_string(data_i.tolist())\n",
    "    data_i = data_i.unsqueeze(0)\n",
    "    hidden_acts_transfo = model(data_i, act=True) # (B, L, n_neurones)\n",
    "    print_color(city_name, hidden_acts_transfo[0, :, id_hidden_activation].tolist()[:len(city_name)])\n",
    "\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez avec différents neurones, en vous concentrant sur ceux ayant obtenu les plus grandes valeurs d'activation sur l'ensemble des neurones, de trouver des concepts explicites si cela est possible. Si oui, alors vous avez trouvé des neurones \"monosémantique\", sinon, vous constatetez leur caractère \"polysémantique\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCICE(S) : Concepts interprétables grâce au SAE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe est exactement le même qu'avec les neurones de la couche cachée dans le Transformer, mais on regarde maintenant dans l'espace des activations du SAE avec les neurones de la couche cachée du SAE.\n",
    "\n",
    "Retrouver les plus grandes valeurs d'activation des neurones cachés du SEA nn modifiant légèrement le code utilisé pour trouver celles des neurones cachés du Transformer,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les plus petites valeurs possibles\n",
    "top_values_sae = torch.full((sae.num_features, top_k), -float('inf'))\n",
    "# indices à -1 (le dernier) du fait que les plus petites valeurs seront classées en dernier dans top_values_sae\n",
    "top_indices_sae = torch.full((sae.num_features, top_k), -1, dtype=torch.long)\n",
    "\n",
    "#Pour chaque élément du jeu de données d'entrainement\n",
    "for X, _ in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "    # par lot\n",
    "    X = X.to(device)\n",
    "\n",
    "    ### EXERCICE : compléter ce bloc avec les bonnes instructions \n",
    "    # DEBUT DE BLOC\n",
    "    \n",
    "    ### EXERCICE : à compléter\n",
    "\n",
    "    # FIN DE BLOC\n",
    "\n",
    "clean_memory(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des k neurones cachés du SAE ayant les plus fortes activations, et les indices (dans le jeu d'entrainement) des noms de communes associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_activations_sae, indices_sae = top_values_sae[:, 0].topk(k=20)\n",
    "print(\"valeurs maximales : \", max_activations_sae.tolist())\n",
    "print(\"indices des caractéristiques correspondantes : \", indices_sae.tolist())\n",
    "max_activations_indices_sae = top_indices_sae[indices][0].tolist()\n",
    "print(\"indices des noms de communes dans le jeu d'entrainement\", max_activations_indices_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_feature = indices_sae[0]\n",
    "for i in top_indices_sae[idx_feature]:\n",
    "    data_i, _ = train_dataset[i.item()]\n",
    "    data_i = data_i.to(device)\n",
    "    city_name = tokenizer.to_string(data_i.tolist())\n",
    "    data_i = data_i.unsqueeze(0)\n",
    "    hidden_acts_transfo = model(data_i, act=True) # (B, S, n_features)\n",
    "    _, _, features, _, _ = sae(hidden_acts_transfo)\n",
    "    print_color(city_name, features[0, :, idx_feature].tolist()[:len(city_name)])\n",
    "\n",
    "clean_memory(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity_cnn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

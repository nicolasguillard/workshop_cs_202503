{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop CentraleSupélec - CeSIA\n",
    "\n",
    "- Création : 02/2025 par [Nicolas Guillard](mailto:nicolas.guillar@securite-ia.fr) - bénévole au [CeSIA](https://www.securite-ia.fr/).\n",
    "\n",
    "Créer en adaptant et complétant le projet [Générer des noms de villes et communes françaises](https://github.com/alxndrTL/villes) par [Alexandre TL](https://www.youtube.com/@alexandretl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation du sujet et Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les éléments de ce TP :\n",
    "- le présent carnet\n",
    "- le répertoire `utils` et les fichiers contenus\n",
    "- le fichier de données\n",
    "- le répertoire `weights` contenant les poids des modèles utiles et ceux produits\n",
    "\n",
    "### Pour cette partie :\n",
    "Exécuter les différentes bloc de code successivement afin de découvrir le jeu de donnée et son traitement afin de produire des séquences pour le modèle Transformer.\n",
    "\n",
    "Certains constats vous permettront d'apprécier les résultats obtenus dans les parties suivantes en connaissant la référence \"vérité terrain\".\n",
    "\n",
    "Le jeu de données contient 36583 noms de commune française."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les modules et paramétrages globaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modules nécessaires sont importés. A moins d'un besoin spécifique, il n'y aura pas besoin de modifier le bloc de code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules prédéfinis et tiers\n",
    "import math\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules créés pour le projet \n",
    "from utils import print_colore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélection du GPU selon l'environnement de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramétrages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer la limite du nombre maximal de lignes affichées dans un tableau pandas\n",
    "pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer le thème de seaborn\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrer les graines aléatoires\n",
    "pth_rnd_gen = torch.Generator(device).manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"./villes.txt\", header=None, names=[\"nom\"])\n",
    "display(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons les premières informations structurelles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution de la longueur des noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la longueur des chaînes de caractères dans la colonne \"nom\"\n",
    "df['length'] = df['nom'].apply(len)\n",
    "\n",
    "# Afficher la distribution de la longueur des chaînes de caractères\n",
    "length_distribution = df['length'].value_counts().sort_index()\n",
    "#print(length_distribution)\n",
    "\n",
    "# Afficher la distribution sous forme d'un histogramme\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=length_distribution.index, y=length_distribution.values, hue=length_distribution.values, palette=\"coolwarm\")\n",
    "plt.xlabel('Longueur des chaînes de caractères')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution de la longueur des chaînes de caractères')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fréquences des caractères dans les noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer toutes les chaînes de caractères de la colonne \"nom\"\n",
    "all_chars = ''.join(df['nom'])\n",
    "\n",
    "# Compter les occurrences de chaque caractère\n",
    "char_counts = Counter(all_chars)\n",
    "\n",
    "# Convertir le résultat en dataframe pour une meilleure lisibilité\n",
    "char_freq_df = pd.DataFrame(\n",
    "    char_counts.items(), columns=['Caractère', 'Fréquence']\n",
    "    ).sort_values(by='Fréquence', ascending=False)\n",
    "\n",
    "print(\"Nombre de caractères distincts :\", len(char_freq_df))\n",
    "display(char_freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taux de fréquence par rapport aux (dix premières) positions dans la chaîne de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiter la longueur des noms à 10 caractères\n",
    "df['nom_limited'] = df['nom'].str[:10]\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les fréquences des caractères par position\n",
    "position_char_freq = {i: Counter() for i in range(10)}\n",
    "\n",
    "# Remplir le dictionnaire avec les fréquences des caractères par position\n",
    "for name in df['nom_limited']:\n",
    "    for i, char in enumerate(name):\n",
    "        position_char_freq[i][char] += 1\n",
    "\n",
    "# Convertir le dictionnaire en dataframe pour une meilleure lisibilité\n",
    "position_char_freq_df = pd.DataFrame(position_char_freq).fillna(0).astype(int)\n",
    "\n",
    "# Limiter aux 15 premiers caractères les plus fréquents\n",
    "top_chars = position_char_freq_df.sum(axis=1).sort_values(ascending=False).head(15).index\n",
    "position_char_freq_df = position_char_freq_df.loc[top_chars]\n",
    "\n",
    "# Calculer le taux de présence par position\n",
    "position_char_rate_df = position_char_freq_df.div(position_char_freq_df.sum(axis=0), axis=1) * 100\n",
    "\n",
    "# Visualiser les taux de présence avec une carte de chaleur\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(position_char_rate_df, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Caractère')\n",
    "plt.title('Taux de présence des caractères par position (limité aux 10 premières positions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fréquence des composants de nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les chaînes de caractères par \"-\" ou \" \" et les concaténer\n",
    "element_separator = \"-' \"\n",
    "all_elements = ' '.join(df['nom'].str.replace(f\"[{element_separator}]\", \" \", regex=True).values).split()\n",
    "\n",
    "# Compter les occurrences de chaque élément\n",
    "element_counts = Counter(all_elements)\n",
    "\n",
    "# Convertir le résultat en dataframe pour une meilleure lisibilité\n",
    "element_freq_df = pd.DataFrame(element_counts.items(), columns=['Élément', 'Fréquence']).sort_values(by='Fréquence', ascending=False)\n",
    "\n",
    "print(f\"Nombre total de composants distincts : {len(element_freq_df)}\")\n",
    "display(element_freq_df.sample(15).sort_values(by='Fréquence', ascending=False))\n",
    "\n",
    "# Filtrer les éléments dont la fréquence est supérieure à 1\n",
    "element_freq_sup_1_df = element_freq_df[element_freq_df['Fréquence'] > 1]\n",
    "\n",
    "# Afficher le nombre total d'éléments associés\n",
    "print(f\"Nombre total de composants présents plus d'une fois : {len(element_freq_sup_1_df)}\")\n",
    "display(element_freq_sup_1_df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de noms de communes sont composées ?\n",
    "Quelle est la distribution du nombre de composants ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de composants pour chaque nom\n",
    "df['num_components'] = df['nom'].apply(lambda x: len([comp for comp in x if comp in element_separator]) + 1)\n",
    "\n",
    "# Afficher la distribution du taux de fréquence du nombre de composants\n",
    "component_distribution = df['num_components'].value_counts().sort_index()\n",
    "component_distribution_rate = component_distribution / len(df) * 100\n",
    "display(component_distribution.to_frame())\n",
    "\n",
    "# Afficher la distribution sous forme d'un histogramme\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=component_distribution_rate.index, y=component_distribution_rate.values, hue=component_distribution_rate.values, palette=\"coolwarm\")\n",
    "for i in range(len(component_distribution_rate)):\n",
    "    plt.text(i, component_distribution_rate.values[i] + 0.5, f'{component_distribution_rate.values[i]:.3f}%', ha='center')\n",
    "plt.xlabel('Nombre de composants')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution de la fréquence du nombre de composants')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de la classe fournissant les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"<pad>\" # Padding\n",
    "SOS = \"<SOS>\" # Start Of Sequence\n",
    "EOS = \"<EOS>\" # End Of Sequence\n",
    "\n",
    "class CityNameDataset():\n",
    "    def __init__(self, file_name: str = \"villes.txt\", split_rate: float =0.9, device=\"cpu\"):\n",
    "\n",
    "        # chargement des données\n",
    "        fichier = open(file_name)\n",
    "        donnees = fichier.read()\n",
    "        villes = donnees.replace('\\n', ',').split(',')\n",
    "        # mise à l'écart des villes avec un nom de longueur inférieure à 3\n",
    "        self.villes = [ville for ville in villes if len(ville) > 2]\n",
    "\n",
    "        # création du vocabulaire\n",
    "        self.vocabulaire = sorted(list(set(''.join(villes))))\n",
    "        self.vocabulaire = [PAD, SOS, EOS] + self.vocabulaire\n",
    "        # <SOS> et <EOS> sont ajoutés respectivement au début et à la fin de chaque séquence\n",
    "        # <pad> est utilisé pour faire en sorte que toutes les séquences aient la même longueur\n",
    "\n",
    "        # pour convertir char <-> int\n",
    "        self.char_to_int = {}\n",
    "        self.int_to_char = {}\n",
    "\n",
    "        for (c, i) in tqdm(zip(self.vocabulaire, range(len(self.vocabulaire))), desc=\"creating vocabulary\", total=len(self.vocabulaire)):\n",
    "            self.char_to_int[c] = i\n",
    "            self.int_to_char[i] = c\n",
    "\n",
    "        num_sequences = len(villes)\n",
    "        self.max_len = max([len(ville) for ville in villes]) + 2 # <SOS> et <EOS>\n",
    "\n",
    "        X = torch.zeros((num_sequences, self.max_len), dtype=torch.int32, device=device)\n",
    "\n",
    "        # création des séquences\n",
    "        for i in trange(num_sequences, desc=\"creatind dataset\"):\n",
    "            X[i] = torch.tensor([self.char_to_int[SOS]] +\n",
    "                                [self.char_to_int[c] for c in villes[i]] +\n",
    "                                [self.char_to_int[EOS]] +\n",
    "                                [self.char_to_int[PAD]] * (self.max_len - len(villes[i]) - 2))\n",
    "\n",
    "        # jeu de données d'entrainement et de validation\n",
    "        n_split = int(split_rate * X.shape[0])\n",
    "\n",
    "        idx_permut = torch.randperm(X.shape[0])\n",
    "        idx_train, _ = torch.sort(idx_permut[:n_split])\n",
    "        idx_val, _ = torch.sort(idx_permut[n_split:])\n",
    "\n",
    "        self.X_train = X[idx_train]\n",
    "        self.X_val = X[idx_val]\n",
    "\n",
    "    def get_batch(self, batch_size: int, split : str=\"val\", device=None) -> torch.Tensor:\n",
    "        assert split in [\"train\", \"val\"], f\"split ({split}) should be 'train' or 'val'.\" \n",
    "\n",
    "        data = self.X_train if split == 'train' else self.X_val\n",
    "\n",
    "        idx = torch.randint(low=int(batch_size/2), high=int(data.shape[0]-batch_size/2), size=(1,), dtype=torch.int32).item()\n",
    "\n",
    "        batch = data[int(idx-batch_size/2):int(idx+batch_size/2)]\n",
    "        X = batch[:, :-1] # (B, S=max_len-1) : (max(len(\"nom\")) + 2) - 1\n",
    "        Y = batch[:, 1:] # (B, S=max_len-1)\n",
    "        if device:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "        return X, Y.long()\n",
    "    \n",
    "    def cast_char_to_int(self, sequence: list[str]) -> list[int]:\n",
    "        return [self.char_to_int[c] for c in sequence]\n",
    "    \n",
    "    def cast_int_to_char(self, sequence: list[int]) -> list[str]:\n",
    "        return [self.int_to_char[i] for i in sequence]\n",
    "    \n",
    "    def to_string(self, sequence: list[int]) -> str:\n",
    "        return \"\".join([self.int_to_char[i] for i in sequence if i > 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CityNameDataset(device=device) # toute la partie données de 2_mlp.py a été encapsulée dans l'objet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, Y = batch = dataset.get_batch(batch_size=2)\n",
    "print(\"> X (ids):\", x.to(\"cpu\"), sep=\"\\n\")\n",
    "print(\"> caractères correspondants pour la première séquence :\", dataset.cast_int_to_char(x[0].to(\"cpu\").tolist()), sep=\"\\n\")\n",
    "print(\"> nom :\", dataset.to_string(x.to(\"cpu\")[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
